{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('TkAgg')\n",
    "rc_fonts = {\"text.usetex\": True, \"font.size\": 30, 'mathtext.default': 'regular', 'axes.titlesize': 33, \"axes.labelsize\": 33, \"legend.fontsize\": 30, \"xtick.labelsize\": 30, \"ytick.labelsize\": 30, 'figure.titlesize': 33, 'figure.figsize': (15, 9.3), 'text.latex.preamble': [\n",
    "    r'\\usepackage{amsmath,amssymb,bm,physics,lmodern}'], \"font.family\": \"serif\", \"font.serif\": \"computer modern roman\", }\n",
    "mpl.rcParams.update(rc_fonts)\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde as KDE\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def produce_raw_data_sets(frac_for_testing=0.6):\n",
    "    \"\"\"\n",
    "    Produces the training, testing, and validation datasets.\n",
    "    :param frac_for_testing: Float, Fractional divide between train and test.\n",
    "    :return: List of 3 Dataframes, Training, Testing, Validation.\n",
    "    \"\"\"\n",
    "    conversation_id = 0\n",
    "    n_to_drop = {'good':31, 'bad': 8}  # The number reserved for validation\n",
    "    frac_for_train = 0.6  # The fraction for training wrt testing.\n",
    "    df_train, df_test, df_validate = [], [], []\n",
    "    for f_name, drop_num in n_to_drop.items():\n",
    "        df1 = pd.read_excel('raw/{}.xlsx'.format(f_name))\n",
    "        df = df1\n",
    "        df_cols = ['word', 'from', 'to', 'speaker', 'gap']\n",
    "        df = df[1:]\n",
    "        df.columns = range(df.shape[1])\n",
    "        words = list(df[0])\n",
    "        words = [int(x) if pd.notnull(x) else x for x in words]\n",
    "        df = df.drop([0], 1)\n",
    "        dfs = [df[[i for i in range(j, j+len(df_cols[1:]))]] for j in range(1, max(df.columns), len(df_cols[1:]))]\n",
    "        for i in range(len(dfs)):\n",
    "            d = dfs[i]\n",
    "            d.columns = df_cols[1:]\n",
    "            dfs[i] = d.assign(id=conversation_id)\n",
    "            conversation_id += 1\n",
    "        df = pd.concat(dfs,ignore_index=True)\n",
    "        df = df.assign(word=words*len(dfs))\n",
    "        df = df.assign(type=f_name)\n",
    "        df_validate.append(df[:len(words)*drop_num])\n",
    "        df_include = df[len(words)*drop_num:]\n",
    "        ids_train = {k:np.random.random() <= frac_for_train for k in list(set(df_include['id']))}\n",
    "        df_train.append(df_include[df_include['id'].map(ids_train).values])\n",
    "        df_test.append(df_include[np.invert(df_include['id'].map(ids_train).values)])\n",
    "    df_train, df_test, df_validate = [pd.concat(d, ignore_index=True) for d in [df_train, df_test, df_validate]]\n",
    "    return df_train, df_test, df_validate\n",
    "\n",
    "\n",
    "def make_features(df):\n",
    "    \"\"\"\n",
    "    Adds features for prediction to a data set.\n",
    "    :param df: DataFrame.\n",
    "    :return: List, DataFrames with the new features as columns.\n",
    "    \"\"\"\n",
    "    ids = set(df['id'])\n",
    "    dfs = []\n",
    "    for id in ids:\n",
    "        d = df[df['id'] == id]\n",
    "        d = d.assign(sentence=d['speaker'])\n",
    "        d['sentence'] = [0] + list(np.diff(d['sentence']))\n",
    "        d['sentence'] = 1.0*(d['sentence'] != 0)\n",
    "        d['sentence'] = np.cumsum(d['sentence'])\n",
    "        g = d.groupby(['sentence'])\n",
    "        f = g.apply(lambda x: [x.shape[0], np.ptp(x['from']), np.mean(x['gap']), list(x['type'])[0]])\n",
    "        d = pd.DataFrame(list(f.values), columns=['n_words', 'duration', 'gap', 'type'])\n",
    "        d.index.name = 'sentence'\n",
    "        d = d.dropna()  # This way of dropping NAN might be a bit too aggressive.\n",
    "        d = d.drop(0)  # We drop the opening sentences as they have zero gaps\n",
    "        d = d[d['duration'] > 0]  # durations of Zero make no sense.\n",
    "        dfs.append(d)\n",
    "    # types = [list(set(d['type']))[0] for d in dfs]\n",
    "    # g = pd.concat(dfs)\n",
    "    return ids, dfs\n",
    "    # b = g[g['type'] == 'bad']\n",
    "    # g = g[g['type'] == 'good']\n",
    "    # x = np.linspace(-6, 7, 1000)\n",
    "    # f = ['n_words', 'gap', 'duration'][-1]\n",
    "    # plt.clf()\n",
    "    # plt.hist(np.log(g[f]), normed=True, label='Good', bins=100,alpha=0.5)\n",
    "    # plt.hist(np.log(b[f]), normed=True, label='Bad', bins=100, alpha=0.5)\n",
    "    # plt.plot(x, KDE(np.log(g[f]))(x))\n",
    "    # plt.plot(x, KDE(np.log(b[f]))(x))\n",
    "    # plt.legend()\n",
    "\n",
    "#df_train, df_test, df_validate = produce_raw_data_sets()\n",
    "\n",
    "# _, d_train = make_features(df_train)\n",
    "# _, d_test = make_features(df_test)\n",
    "# _, d_validate = make_features(df_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {'train': d_train,\n",
    "              'test': d_test,\n",
    "              'validate': d_validate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df_array in dataframes.items():\n",
    "    \n",
    "    for i, df in enumerate(df_array):\n",
    "        dataframes[name][i] = df.reset_index().set_index(['conversation', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train, d_test, d_validate = pd.concat(dataframes['train']), pd.concat(dataframes['test']), pd.concat(dataframes['validate'])\n",
    "\n",
    "dfs = [d_train, d_test, d_validate]\n",
    "\n",
    "d_train = d_train.reset_index().rename(columns={'sentence': 'segment'})\n",
    "d_train = d_train.set_index(['conversation', 'segment'])\n",
    "d_test = d_test.reset_index().rename(columns={'sentence': 'segment'})\n",
    "d_test = d_test.set_index(['conversation', 'segment'])\n",
    "d_validate = d_validate.reset_index().rename(columns={'sentence': 'segment'})\n",
    "d_validate = d_validate.set_index(['conversation', 'segment'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-a3ecf9ffab9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./processed/d_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./processed/d_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0md_validate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./processed/d_validate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd_train' is not defined"
     ]
    }
   ],
   "source": [
    "d_train.to_csv('./processed/d_train')\n",
    "d_test.to_csv('./processed/d_test')\n",
    "d_validate.to_csv('./processed/d_validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child_interview 0\n",
      "cbt_session 0\n"
     ]
    }
   ],
   "source": [
    "child_interview = pd.read_csv('raw/Child_interview.csv')\n",
    "cbt_session = pd.read_csv('raw/cbt_session.csv')\n",
    "\n",
    "real_dfs = {'child_interview': child_interview,\n",
    "            'cbt_session': cbt_session}\n",
    "\n",
    "for name, df in real_dfs.items():\n",
    "    print(name, 0)\n",
    "    df['id'] = 1\n",
    "    df.rename(columns={'TimeFrom': 'from',\n",
    "                       'TimeTo': 'to',\n",
    "                       'Gap between speakers': 'gap',\n",
    "                       'Speaker': 'speaker'}, inplace=True)\n",
    "    df['type'] = 'Unknown'\n",
    "    _, real_dfs[name] = make_features(df)\n",
    "    \n",
    "    real_dfs[name] = real_dfs[name][0]\n",
    "    real_dfs[name].drop(['type'], axis=1, inplace=True)\n",
    "\n",
    "    real_dfs[name].to_pickle('./processed/real/{}'.format(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
